{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_location(frame, location):\n",
    "    frame[\"location\"] = location\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeNaN(frame):\n",
    "    frame = frame.fillna(method=\"ffill\")\n",
    "    frame = frame.fillna(method=\"bfill\")\n",
    "    frame = frame.fillna(value=0)\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "def averageFeatures(frame):\n",
    "    frame[\"date_forecast\"] = frame[\"date_forecast\"].apply(lambda a : a.replace(minute=0))\n",
    "    return frame.groupby([\"date_forecast\"])[frame.iloc[:,1:].columns].mean().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bm/37km6rb530l8y0vv0znc0zb00000gn/T/ipykernel_69750/3652912417.py:2: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  frame = frame.fillna(method=\"ffill\")\n",
      "/var/folders/bm/37km6rb530l8y0vv0znc0zb00000gn/T/ipykernel_69750/3652912417.py:3: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  frame = frame.fillna(method=\"bfill\")\n",
      "/var/folders/bm/37km6rb530l8y0vv0znc0zb00000gn/T/ipykernel_69750/3652912417.py:2: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  frame = frame.fillna(method=\"ffill\")\n",
      "/var/folders/bm/37km6rb530l8y0vv0znc0zb00000gn/T/ipykernel_69750/3652912417.py:3: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  frame = frame.fillna(method=\"bfill\")\n",
      "/var/folders/bm/37km6rb530l8y0vv0znc0zb00000gn/T/ipykernel_69750/3652912417.py:2: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  frame = frame.fillna(method=\"ffill\")\n",
      "/var/folders/bm/37km6rb530l8y0vv0znc0zb00000gn/T/ipykernel_69750/3652912417.py:3: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  frame = frame.fillna(method=\"bfill\")\n",
      "/var/folders/bm/37km6rb530l8y0vv0znc0zb00000gn/T/ipykernel_69750/3652912417.py:2: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  frame = frame.fillna(method=\"ffill\")\n",
      "/var/folders/bm/37km6rb530l8y0vv0znc0zb00000gn/T/ipykernel_69750/3652912417.py:3: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  frame = frame.fillna(method=\"bfill\")\n",
      "/var/folders/bm/37km6rb530l8y0vv0znc0zb00000gn/T/ipykernel_69750/3652912417.py:2: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  frame = frame.fillna(method=\"ffill\")\n",
      "/var/folders/bm/37km6rb530l8y0vv0znc0zb00000gn/T/ipykernel_69750/3652912417.py:3: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  frame = frame.fillna(method=\"bfill\")\n",
      "/var/folders/bm/37km6rb530l8y0vv0znc0zb00000gn/T/ipykernel_69750/3652912417.py:2: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  frame = frame.fillna(method=\"ffill\")\n",
      "/var/folders/bm/37km6rb530l8y0vv0znc0zb00000gn/T/ipykernel_69750/3652912417.py:3: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  frame = frame.fillna(method=\"bfill\")\n"
     ]
    }
   ],
   "source": [
    "train_a = pd.read_parquet('A/train_targets.parquet')\n",
    "X_train_estimated_a = pd.read_parquet('A/X_train_estimated.parquet')\n",
    "X_train_observed_a = pd.read_parquet('A/X_train_observed.parquet')\n",
    "\n",
    "train_b = pd.read_parquet('B/train_targets.parquet')\n",
    "X_train_estimated_b = pd.read_parquet('B/X_train_estimated.parquet')\n",
    "X_train_observed_b = pd.read_parquet('B/X_train_observed.parquet')\n",
    "\n",
    "train_c = pd.read_parquet('C/train_targets.parquet')\n",
    "X_train_estimated_c = pd.read_parquet('C/X_train_estimated.parquet')\n",
    "X_train_observed_c = pd.read_parquet('C/X_train_observed.parquet')\n",
    "\n",
    "train_a = add_location(train_a, \"A\")\n",
    "train_b = add_location(train_b, \"B\")\n",
    "train_c = add_location(train_c, \"C\")\n",
    "X_train_estimated_a = X_train_estimated_a.iloc[:,1:]\n",
    "X_train_estimated_b = X_train_estimated_b.iloc[:,1:]\n",
    "X_train_estimated_c = X_train_estimated_c.iloc[:,1:]\n",
    "X_train_estimated_a = add_location(averageFeatures(removeNaN(X_train_estimated_a)), \"A\")\n",
    "X_train_estimated_b = add_location(averageFeatures(removeNaN(X_train_estimated_b)), \"B\")\n",
    "X_train_estimated_c = add_location(averageFeatures(removeNaN(X_train_estimated_c)), \"C\")\n",
    "X_train_observed_a = add_location(averageFeatures(removeNaN(X_train_observed_a)), \"A\")\n",
    "X_train_observed_b = add_location(averageFeatures(removeNaN(X_train_observed_b)), \"B\")\n",
    "X_train_observed_c = add_location(averageFeatures(removeNaN(X_train_observed_c)), \"C\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>absolute_humidity_2m:gm3</th>\n",
       "      <th>air_density_2m:kgm3</th>\n",
       "      <th>ceiling_height_agl:m</th>\n",
       "      <th>clear_sky_energy_1h:J</th>\n",
       "      <th>clear_sky_rad:W</th>\n",
       "      <th>cloud_base_agl:m</th>\n",
       "      <th>dew_or_rime:idx</th>\n",
       "      <th>dew_point_2m:K</th>\n",
       "      <th>diffuse_rad:W</th>\n",
       "      <th>diffuse_rad_1h:J</th>\n",
       "      <th>direct_rad:W</th>\n",
       "      <th>direct_rad_1h:J</th>\n",
       "      <th>effective_cloud_cover:p</th>\n",
       "      <th>elevation:m</th>\n",
       "      <th>fresh_snow_12h:cm</th>\n",
       "      <th>fresh_snow_1h:cm</th>\n",
       "      <th>fresh_snow_24h:cm</th>\n",
       "      <th>fresh_snow_3h:cm</th>\n",
       "      <th>fresh_snow_6h:cm</th>\n",
       "      <th>is_day:idx</th>\n",
       "      <th>is_in_shadow:idx</th>\n",
       "      <th>msl_pressure:hPa</th>\n",
       "      <th>precip_5min:mm</th>\n",
       "      <th>precip_type_5min:idx</th>\n",
       "      <th>pressure_100m:hPa</th>\n",
       "      <th>pressure_50m:hPa</th>\n",
       "      <th>prob_rime:p</th>\n",
       "      <th>rain_water:kgm2</th>\n",
       "      <th>relative_humidity_1000hPa:p</th>\n",
       "      <th>sfc_pressure:hPa</th>\n",
       "      <th>snow_density:kgm3</th>\n",
       "      <th>snow_depth:cm</th>\n",
       "      <th>snow_drift:idx</th>\n",
       "      <th>snow_melt_10min:mm</th>\n",
       "      <th>snow_water:kgm2</th>\n",
       "      <th>sun_azimuth:d</th>\n",
       "      <th>sun_elevation:d</th>\n",
       "      <th>super_cooled_liquid_water:kgm2</th>\n",
       "      <th>t_1000hPa:K</th>\n",
       "      <th>total_cloud_cover:p</th>\n",
       "      <th>visibility:m</th>\n",
       "      <th>wind_speed_10m:ms</th>\n",
       "      <th>wind_speed_u_10m:ms</th>\n",
       "      <th>wind_speed_v_10m:ms</th>\n",
       "      <th>wind_speed_w_1000hPa:ms</th>\n",
       "      <th>location</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.302498</td>\n",
       "      <td>-2.119255</td>\n",
       "      <td>-0.191941</td>\n",
       "      <td>1.295913</td>\n",
       "      <td>1.567624</td>\n",
       "      <td>0.379387</td>\n",
       "      <td>-0.025048</td>\n",
       "      <td>2.334257</td>\n",
       "      <td>0.503001</td>\n",
       "      <td>0.453502</td>\n",
       "      <td>2.974433</td>\n",
       "      <td>2.546436</td>\n",
       "      <td>-1.890200</td>\n",
       "      <td>-0.685242</td>\n",
       "      <td>-0.147474</td>\n",
       "      <td>-0.090404</td>\n",
       "      <td>-0.187099</td>\n",
       "      <td>-0.103521</td>\n",
       "      <td>-0.120029</td>\n",
       "      <td>1.062234</td>\n",
       "      <td>-1.166938</td>\n",
       "      <td>0.762895</td>\n",
       "      <td>-0.193076</td>\n",
       "      <td>-0.254395</td>\n",
       "      <td>0.845194</td>\n",
       "      <td>0.819852</td>\n",
       "      <td>-0.14232</td>\n",
       "      <td>-0.233200</td>\n",
       "      <td>-0.742403</td>\n",
       "      <td>0.788712</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.153735</td>\n",
       "      <td>-0.005459</td>\n",
       "      <td>-0.064067</td>\n",
       "      <td>-0.380596</td>\n",
       "      <td>-0.736486</td>\n",
       "      <td>1.309619</td>\n",
       "      <td>-0.537932</td>\n",
       "      <td>2.612505</td>\n",
       "      <td>-2.028697</td>\n",
       "      <td>1.098311</td>\n",
       "      <td>-0.902113</td>\n",
       "      <td>-0.441818</td>\n",
       "      <td>-1.056949</td>\n",
       "      <td>0.000961</td>\n",
       "      <td>-1.143293</td>\n",
       "      <td>0.289431</td>\n",
       "      <td>-0.649731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.881699</td>\n",
       "      <td>0.685028</td>\n",
       "      <td>-0.852774</td>\n",
       "      <td>-0.629232</td>\n",
       "      <td>-0.627553</td>\n",
       "      <td>-0.539633</td>\n",
       "      <td>-0.025048</td>\n",
       "      <td>-0.862049</td>\n",
       "      <td>-0.651153</td>\n",
       "      <td>-0.658957</td>\n",
       "      <td>-0.444724</td>\n",
       "      <td>-0.450531</td>\n",
       "      <td>0.642259</td>\n",
       "      <td>-0.558237</td>\n",
       "      <td>-0.147474</td>\n",
       "      <td>-0.090404</td>\n",
       "      <td>-0.187099</td>\n",
       "      <td>-0.103521</td>\n",
       "      <td>-0.120029</td>\n",
       "      <td>-0.995419</td>\n",
       "      <td>0.902728</td>\n",
       "      <td>-0.693514</td>\n",
       "      <td>-0.193076</td>\n",
       "      <td>-0.254395</td>\n",
       "      <td>-0.668247</td>\n",
       "      <td>-0.652292</td>\n",
       "      <td>-0.14232</td>\n",
       "      <td>-0.233200</td>\n",
       "      <td>0.711439</td>\n",
       "      <td>-0.644171</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.153735</td>\n",
       "      <td>-0.005459</td>\n",
       "      <td>-0.064067</td>\n",
       "      <td>-0.168525</td>\n",
       "      <td>-1.508877</td>\n",
       "      <td>-1.300690</td>\n",
       "      <td>0.407943</td>\n",
       "      <td>-1.074586</td>\n",
       "      <td>0.453369</td>\n",
       "      <td>0.070423</td>\n",
       "      <td>-0.219559</td>\n",
       "      <td>0.156150</td>\n",
       "      <td>0.915281</td>\n",
       "      <td>0.000961</td>\n",
       "      <td>0.107764</td>\n",
       "      <td>-1.098440</td>\n",
       "      <td>-1.516853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.818675</td>\n",
       "      <td>-0.730792</td>\n",
       "      <td>-0.633792</td>\n",
       "      <td>-0.097363</td>\n",
       "      <td>-0.324585</td>\n",
       "      <td>-0.383719</td>\n",
       "      <td>-0.025048</td>\n",
       "      <td>1.536098</td>\n",
       "      <td>-0.082344</td>\n",
       "      <td>0.223826</td>\n",
       "      <td>-0.405502</td>\n",
       "      <td>-0.354769</td>\n",
       "      <td>0.926075</td>\n",
       "      <td>-0.685242</td>\n",
       "      <td>-0.147474</td>\n",
       "      <td>-0.090404</td>\n",
       "      <td>-0.187099</td>\n",
       "      <td>-0.103521</td>\n",
       "      <td>-0.120029</td>\n",
       "      <td>1.062234</td>\n",
       "      <td>-1.166938</td>\n",
       "      <td>1.051882</td>\n",
       "      <td>-0.193076</td>\n",
       "      <td>-0.254395</td>\n",
       "      <td>1.134020</td>\n",
       "      <td>1.118879</td>\n",
       "      <td>-0.14232</td>\n",
       "      <td>-0.233200</td>\n",
       "      <td>0.556738</td>\n",
       "      <td>1.105431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.153735</td>\n",
       "      <td>-0.005459</td>\n",
       "      <td>-0.064067</td>\n",
       "      <td>-0.380596</td>\n",
       "      <td>1.134056</td>\n",
       "      <td>0.342227</td>\n",
       "      <td>-0.537932</td>\n",
       "      <td>1.123856</td>\n",
       "      <td>0.773731</td>\n",
       "      <td>0.489176</td>\n",
       "      <td>-1.570448</td>\n",
       "      <td>-0.147296</td>\n",
       "      <td>-0.417307</td>\n",
       "      <td>0.000961</td>\n",
       "      <td>-1.143293</td>\n",
       "      <td>0.435523</td>\n",
       "      <td>0.939991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.546826</td>\n",
       "      <td>-0.532442</td>\n",
       "      <td>-0.484097</td>\n",
       "      <td>-0.584660</td>\n",
       "      <td>-0.520236</td>\n",
       "      <td>-0.655065</td>\n",
       "      <td>-0.025048</td>\n",
       "      <td>0.657388</td>\n",
       "      <td>-0.453558</td>\n",
       "      <td>-0.554677</td>\n",
       "      <td>-0.428326</td>\n",
       "      <td>-0.442008</td>\n",
       "      <td>0.743674</td>\n",
       "      <td>-0.685242</td>\n",
       "      <td>-0.147474</td>\n",
       "      <td>-0.090404</td>\n",
       "      <td>-0.187099</td>\n",
       "      <td>-0.103521</td>\n",
       "      <td>-0.120029</td>\n",
       "      <td>1.062234</td>\n",
       "      <td>-1.166938</td>\n",
       "      <td>-0.444719</td>\n",
       "      <td>-0.193076</td>\n",
       "      <td>-0.254395</td>\n",
       "      <td>-0.379422</td>\n",
       "      <td>-0.380099</td>\n",
       "      <td>-0.14232</td>\n",
       "      <td>-0.233200</td>\n",
       "      <td>0.968103</td>\n",
       "      <td>-0.386596</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.153735</td>\n",
       "      <td>-0.005459</td>\n",
       "      <td>-0.064067</td>\n",
       "      <td>0.043547</td>\n",
       "      <td>-1.428432</td>\n",
       "      <td>0.185245</td>\n",
       "      <td>0.407943</td>\n",
       "      <td>0.272106</td>\n",
       "      <td>0.564320</td>\n",
       "      <td>-1.552874</td>\n",
       "      <td>0.192817</td>\n",
       "      <td>0.959391</td>\n",
       "      <td>-0.110812</td>\n",
       "      <td>0.000961</td>\n",
       "      <td>-1.143293</td>\n",
       "      <td>0.088555</td>\n",
       "      <td>-1.372332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.632859</td>\n",
       "      <td>-0.477725</td>\n",
       "      <td>-0.614942</td>\n",
       "      <td>0.772521</td>\n",
       "      <td>0.887070</td>\n",
       "      <td>-0.208881</td>\n",
       "      <td>-0.025048</td>\n",
       "      <td>-0.517886</td>\n",
       "      <td>1.215252</td>\n",
       "      <td>0.946846</td>\n",
       "      <td>1.313161</td>\n",
       "      <td>1.351461</td>\n",
       "      <td>-0.515624</td>\n",
       "      <td>-0.558237</td>\n",
       "      <td>-0.147474</td>\n",
       "      <td>-0.090404</td>\n",
       "      <td>-0.187099</td>\n",
       "      <td>-0.103521</td>\n",
       "      <td>-0.120029</td>\n",
       "      <td>1.062234</td>\n",
       "      <td>-1.166938</td>\n",
       "      <td>-1.443728</td>\n",
       "      <td>-0.193076</td>\n",
       "      <td>-0.254395</td>\n",
       "      <td>-1.392237</td>\n",
       "      <td>-1.392194</td>\n",
       "      <td>-0.14232</td>\n",
       "      <td>-0.233200</td>\n",
       "      <td>-0.777563</td>\n",
       "      <td>-1.392092</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.153735</td>\n",
       "      <td>-0.005459</td>\n",
       "      <td>-0.064067</td>\n",
       "      <td>-0.380596</td>\n",
       "      <td>-0.175023</td>\n",
       "      <td>0.942882</td>\n",
       "      <td>-0.537932</td>\n",
       "      <td>-0.280382</td>\n",
       "      <td>0.698049</td>\n",
       "      <td>0.878664</td>\n",
       "      <td>0.007959</td>\n",
       "      <td>-1.245059</td>\n",
       "      <td>0.275639</td>\n",
       "      <td>0.000961</td>\n",
       "      <td>0.107764</td>\n",
       "      <td>-0.970610</td>\n",
       "      <td>-0.216171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82606</th>\n",
       "      <td>0.058363</td>\n",
       "      <td>-0.122056</td>\n",
       "      <td>0.342032</td>\n",
       "      <td>0.094530</td>\n",
       "      <td>-0.160097</td>\n",
       "      <td>0.288747</td>\n",
       "      <td>-0.025048</td>\n",
       "      <td>0.225354</td>\n",
       "      <td>0.322767</td>\n",
       "      <td>0.591195</td>\n",
       "      <td>-0.257479</td>\n",
       "      <td>-0.293490</td>\n",
       "      <td>-0.071295</td>\n",
       "      <td>1.600848</td>\n",
       "      <td>-0.147474</td>\n",
       "      <td>-0.090404</td>\n",
       "      <td>-0.187099</td>\n",
       "      <td>-0.103521</td>\n",
       "      <td>-0.120029</td>\n",
       "      <td>1.062234</td>\n",
       "      <td>-1.166938</td>\n",
       "      <td>-0.287787</td>\n",
       "      <td>-0.193076</td>\n",
       "      <td>-0.254395</td>\n",
       "      <td>-0.437187</td>\n",
       "      <td>-0.437605</td>\n",
       "      <td>-0.14232</td>\n",
       "      <td>-0.233200</td>\n",
       "      <td>0.860867</td>\n",
       "      <td>-0.438110</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.153735</td>\n",
       "      <td>-0.005459</td>\n",
       "      <td>-0.064067</td>\n",
       "      <td>-0.380596</td>\n",
       "      <td>0.797337</td>\n",
       "      <td>0.435492</td>\n",
       "      <td>-0.537932</td>\n",
       "      <td>-0.226667</td>\n",
       "      <td>-0.077137</td>\n",
       "      <td>-0.277584</td>\n",
       "      <td>-1.143851</td>\n",
       "      <td>-0.477517</td>\n",
       "      <td>0.049099</td>\n",
       "      <td>0.000961</td>\n",
       "      <td>1.358822</td>\n",
       "      <td>-0.824518</td>\n",
       "      <td>0.650951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82607</th>\n",
       "      <td>-0.098314</td>\n",
       "      <td>0.083134</td>\n",
       "      <td>-1.128082</td>\n",
       "      <td>-0.199079</td>\n",
       "      <td>-0.077360</td>\n",
       "      <td>-0.552454</td>\n",
       "      <td>-0.025048</td>\n",
       "      <td>0.071581</td>\n",
       "      <td>0.008186</td>\n",
       "      <td>-0.084439</td>\n",
       "      <td>0.489284</td>\n",
       "      <td>0.268180</td>\n",
       "      <td>-1.948569</td>\n",
       "      <td>-0.685242</td>\n",
       "      <td>-0.147474</td>\n",
       "      <td>-0.090404</td>\n",
       "      <td>-0.187099</td>\n",
       "      <td>-0.103521</td>\n",
       "      <td>-0.120029</td>\n",
       "      <td>1.062234</td>\n",
       "      <td>-1.166938</td>\n",
       "      <td>-0.069614</td>\n",
       "      <td>-0.193076</td>\n",
       "      <td>-0.254395</td>\n",
       "      <td>-0.027059</td>\n",
       "      <td>-0.025482</td>\n",
       "      <td>-0.14232</td>\n",
       "      <td>-0.233200</td>\n",
       "      <td>0.809885</td>\n",
       "      <td>-0.024082</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.153735</td>\n",
       "      <td>-0.005459</td>\n",
       "      <td>-0.064067</td>\n",
       "      <td>-0.380596</td>\n",
       "      <td>-0.245692</td>\n",
       "      <td>0.480919</td>\n",
       "      <td>-0.537932</td>\n",
       "      <td>-0.295730</td>\n",
       "      <td>-2.156547</td>\n",
       "      <td>0.776563</td>\n",
       "      <td>0.462995</td>\n",
       "      <td>-1.539580</td>\n",
       "      <td>0.288965</td>\n",
       "      <td>0.000961</td>\n",
       "      <td>-1.143293</td>\n",
       "      <td>1.165982</td>\n",
       "      <td>-0.360691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82608</th>\n",
       "      <td>2.482248</td>\n",
       "      <td>-1.134336</td>\n",
       "      <td>2.009449</td>\n",
       "      <td>-0.593378</td>\n",
       "      <td>-0.625249</td>\n",
       "      <td>0.272494</td>\n",
       "      <td>-0.025048</td>\n",
       "      <td>1.891246</td>\n",
       "      <td>-0.647019</td>\n",
       "      <td>-0.550729</td>\n",
       "      <td>-0.444724</td>\n",
       "      <td>-0.425845</td>\n",
       "      <td>-0.549916</td>\n",
       "      <td>-0.685242</td>\n",
       "      <td>-0.147474</td>\n",
       "      <td>-0.090404</td>\n",
       "      <td>-0.187099</td>\n",
       "      <td>-0.103521</td>\n",
       "      <td>-0.120029</td>\n",
       "      <td>-0.481006</td>\n",
       "      <td>0.902728</td>\n",
       "      <td>0.759068</td>\n",
       "      <td>-0.193076</td>\n",
       "      <td>-0.254395</td>\n",
       "      <td>0.856749</td>\n",
       "      <td>0.839021</td>\n",
       "      <td>-0.14232</td>\n",
       "      <td>-0.233200</td>\n",
       "      <td>0.417858</td>\n",
       "      <td>0.819237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.153735</td>\n",
       "      <td>-0.005459</td>\n",
       "      <td>-0.064067</td>\n",
       "      <td>-0.380596</td>\n",
       "      <td>1.569096</td>\n",
       "      <td>0.012383</td>\n",
       "      <td>-0.537932</td>\n",
       "      <td>1.649485</td>\n",
       "      <td>0.163869</td>\n",
       "      <td>0.461337</td>\n",
       "      <td>-0.176900</td>\n",
       "      <td>0.718419</td>\n",
       "      <td>-0.070834</td>\n",
       "      <td>0.000961</td>\n",
       "      <td>-1.143293</td>\n",
       "      <td>0.125078</td>\n",
       "      <td>1.373552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82609</th>\n",
       "      <td>-1.407028</td>\n",
       "      <td>0.643993</td>\n",
       "      <td>0.847784</td>\n",
       "      <td>-0.629232</td>\n",
       "      <td>-0.627553</td>\n",
       "      <td>1.474706</td>\n",
       "      <td>-0.025048</td>\n",
       "      <td>-1.755405</td>\n",
       "      <td>-0.651153</td>\n",
       "      <td>-0.658957</td>\n",
       "      <td>-0.444724</td>\n",
       "      <td>-0.450531</td>\n",
       "      <td>0.715949</td>\n",
       "      <td>-0.558237</td>\n",
       "      <td>-0.147474</td>\n",
       "      <td>-0.090404</td>\n",
       "      <td>1.043988</td>\n",
       "      <td>-0.103521</td>\n",
       "      <td>-0.120029</td>\n",
       "      <td>-0.995419</td>\n",
       "      <td>0.902728</td>\n",
       "      <td>-1.460955</td>\n",
       "      <td>-0.193076</td>\n",
       "      <td>-0.254395</td>\n",
       "      <td>-1.436524</td>\n",
       "      <td>-1.420951</td>\n",
       "      <td>-0.14232</td>\n",
       "      <td>-0.233200</td>\n",
       "      <td>-0.779321</td>\n",
       "      <td>-1.407356</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.153735</td>\n",
       "      <td>-0.005459</td>\n",
       "      <td>-0.064067</td>\n",
       "      <td>-0.380596</td>\n",
       "      <td>0.965445</td>\n",
       "      <td>-0.825508</td>\n",
       "      <td>-0.537932</td>\n",
       "      <td>-1.504297</td>\n",
       "      <td>0.746544</td>\n",
       "      <td>1.292383</td>\n",
       "      <td>0.790052</td>\n",
       "      <td>-1.798402</td>\n",
       "      <td>-0.097486</td>\n",
       "      <td>0.000961</td>\n",
       "      <td>0.107764</td>\n",
       "      <td>-1.317578</td>\n",
       "      <td>0.939991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82610</th>\n",
       "      <td>2.279489</td>\n",
       "      <td>-1.093297</td>\n",
       "      <td>-0.349975</td>\n",
       "      <td>1.110912</td>\n",
       "      <td>1.384921</td>\n",
       "      <td>-0.253595</td>\n",
       "      <td>-0.025048</td>\n",
       "      <td>1.781403</td>\n",
       "      <td>1.326452</td>\n",
       "      <td>0.888933</td>\n",
       "      <td>-0.372042</td>\n",
       "      <td>-0.402022</td>\n",
       "      <td>0.953071</td>\n",
       "      <td>-0.558237</td>\n",
       "      <td>-0.147474</td>\n",
       "      <td>-0.090404</td>\n",
       "      <td>-0.187099</td>\n",
       "      <td>-0.103521</td>\n",
       "      <td>-0.120029</td>\n",
       "      <td>1.062234</td>\n",
       "      <td>-1.166938</td>\n",
       "      <td>0.385874</td>\n",
       "      <td>-0.193076</td>\n",
       "      <td>-0.254395</td>\n",
       "      <td>0.463944</td>\n",
       "      <td>0.449899</td>\n",
       "      <td>-0.14232</td>\n",
       "      <td>1.600272</td>\n",
       "      <td>1.245863</td>\n",
       "      <td>0.433829</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.153735</td>\n",
       "      <td>-0.005459</td>\n",
       "      <td>-0.064067</td>\n",
       "      <td>-0.380596</td>\n",
       "      <td>-0.718394</td>\n",
       "      <td>1.215915</td>\n",
       "      <td>0.407943</td>\n",
       "      <td>1.231286</td>\n",
       "      <td>0.765648</td>\n",
       "      <td>-1.411111</td>\n",
       "      <td>-1.470909</td>\n",
       "      <td>-0.343644</td>\n",
       "      <td>-0.510588</td>\n",
       "      <td>0.000961</td>\n",
       "      <td>0.107764</td>\n",
       "      <td>0.389870</td>\n",
       "      <td>-0.649731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82611 rows Ã— 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       absolute_humidity_2m:gm3  air_density_2m:kgm3  ceiling_height_agl:m  \\\n",
       "0                      3.302498            -2.119255             -0.191941   \n",
       "1                     -0.881699             0.685028             -0.852774   \n",
       "2                      1.818675            -0.730792             -0.633792   \n",
       "3                      0.546826            -0.532442             -0.484097   \n",
       "4                     -0.632859            -0.477725             -0.614942   \n",
       "...                         ...                  ...                   ...   \n",
       "82606                  0.058363            -0.122056              0.342032   \n",
       "82607                 -0.098314             0.083134             -1.128082   \n",
       "82608                  2.482248            -1.134336              2.009449   \n",
       "82609                 -1.407028             0.643993              0.847784   \n",
       "82610                  2.279489            -1.093297             -0.349975   \n",
       "\n",
       "       clear_sky_energy_1h:J  clear_sky_rad:W  cloud_base_agl:m  \\\n",
       "0                   1.295913         1.567624          0.379387   \n",
       "1                  -0.629232        -0.627553         -0.539633   \n",
       "2                  -0.097363        -0.324585         -0.383719   \n",
       "3                  -0.584660        -0.520236         -0.655065   \n",
       "4                   0.772521         0.887070         -0.208881   \n",
       "...                      ...              ...               ...   \n",
       "82606               0.094530        -0.160097          0.288747   \n",
       "82607              -0.199079        -0.077360         -0.552454   \n",
       "82608              -0.593378        -0.625249          0.272494   \n",
       "82609              -0.629232        -0.627553          1.474706   \n",
       "82610               1.110912         1.384921         -0.253595   \n",
       "\n",
       "       dew_or_rime:idx  dew_point_2m:K  diffuse_rad:W  diffuse_rad_1h:J  \\\n",
       "0            -0.025048        2.334257       0.503001          0.453502   \n",
       "1            -0.025048       -0.862049      -0.651153         -0.658957   \n",
       "2            -0.025048        1.536098      -0.082344          0.223826   \n",
       "3            -0.025048        0.657388      -0.453558         -0.554677   \n",
       "4            -0.025048       -0.517886       1.215252          0.946846   \n",
       "...                ...             ...            ...               ...   \n",
       "82606        -0.025048        0.225354       0.322767          0.591195   \n",
       "82607        -0.025048        0.071581       0.008186         -0.084439   \n",
       "82608        -0.025048        1.891246      -0.647019         -0.550729   \n",
       "82609        -0.025048       -1.755405      -0.651153         -0.658957   \n",
       "82610        -0.025048        1.781403       1.326452          0.888933   \n",
       "\n",
       "       direct_rad:W  direct_rad_1h:J  effective_cloud_cover:p  elevation:m  \\\n",
       "0          2.974433         2.546436                -1.890200    -0.685242   \n",
       "1         -0.444724        -0.450531                 0.642259    -0.558237   \n",
       "2         -0.405502        -0.354769                 0.926075    -0.685242   \n",
       "3         -0.428326        -0.442008                 0.743674    -0.685242   \n",
       "4          1.313161         1.351461                -0.515624    -0.558237   \n",
       "...             ...              ...                      ...          ...   \n",
       "82606     -0.257479        -0.293490                -0.071295     1.600848   \n",
       "82607      0.489284         0.268180                -1.948569    -0.685242   \n",
       "82608     -0.444724        -0.425845                -0.549916    -0.685242   \n",
       "82609     -0.444724        -0.450531                 0.715949    -0.558237   \n",
       "82610     -0.372042        -0.402022                 0.953071    -0.558237   \n",
       "\n",
       "       fresh_snow_12h:cm  fresh_snow_1h:cm  fresh_snow_24h:cm  \\\n",
       "0              -0.147474         -0.090404          -0.187099   \n",
       "1              -0.147474         -0.090404          -0.187099   \n",
       "2              -0.147474         -0.090404          -0.187099   \n",
       "3              -0.147474         -0.090404          -0.187099   \n",
       "4              -0.147474         -0.090404          -0.187099   \n",
       "...                  ...               ...                ...   \n",
       "82606          -0.147474         -0.090404          -0.187099   \n",
       "82607          -0.147474         -0.090404          -0.187099   \n",
       "82608          -0.147474         -0.090404          -0.187099   \n",
       "82609          -0.147474         -0.090404           1.043988   \n",
       "82610          -0.147474         -0.090404          -0.187099   \n",
       "\n",
       "       fresh_snow_3h:cm  fresh_snow_6h:cm  is_day:idx  is_in_shadow:idx  \\\n",
       "0             -0.103521         -0.120029    1.062234         -1.166938   \n",
       "1             -0.103521         -0.120029   -0.995419          0.902728   \n",
       "2             -0.103521         -0.120029    1.062234         -1.166938   \n",
       "3             -0.103521         -0.120029    1.062234         -1.166938   \n",
       "4             -0.103521         -0.120029    1.062234         -1.166938   \n",
       "...                 ...               ...         ...               ...   \n",
       "82606         -0.103521         -0.120029    1.062234         -1.166938   \n",
       "82607         -0.103521         -0.120029    1.062234         -1.166938   \n",
       "82608         -0.103521         -0.120029   -0.481006          0.902728   \n",
       "82609         -0.103521         -0.120029   -0.995419          0.902728   \n",
       "82610         -0.103521         -0.120029    1.062234         -1.166938   \n",
       "\n",
       "       msl_pressure:hPa  precip_5min:mm  precip_type_5min:idx  \\\n",
       "0              0.762895       -0.193076             -0.254395   \n",
       "1             -0.693514       -0.193076             -0.254395   \n",
       "2              1.051882       -0.193076             -0.254395   \n",
       "3             -0.444719       -0.193076             -0.254395   \n",
       "4             -1.443728       -0.193076             -0.254395   \n",
       "...                 ...             ...                   ...   \n",
       "82606         -0.287787       -0.193076             -0.254395   \n",
       "82607         -0.069614       -0.193076             -0.254395   \n",
       "82608          0.759068       -0.193076             -0.254395   \n",
       "82609         -1.460955       -0.193076             -0.254395   \n",
       "82610          0.385874       -0.193076             -0.254395   \n",
       "\n",
       "       pressure_100m:hPa  pressure_50m:hPa  prob_rime:p  rain_water:kgm2  \\\n",
       "0               0.845194          0.819852     -0.14232        -0.233200   \n",
       "1              -0.668247         -0.652292     -0.14232        -0.233200   \n",
       "2               1.134020          1.118879     -0.14232        -0.233200   \n",
       "3              -0.379422         -0.380099     -0.14232        -0.233200   \n",
       "4              -1.392237         -1.392194     -0.14232        -0.233200   \n",
       "...                  ...               ...          ...              ...   \n",
       "82606          -0.437187         -0.437605     -0.14232        -0.233200   \n",
       "82607          -0.027059         -0.025482     -0.14232        -0.233200   \n",
       "82608           0.856749          0.839021     -0.14232        -0.233200   \n",
       "82609          -1.436524         -1.420951     -0.14232        -0.233200   \n",
       "82610           0.463944          0.449899     -0.14232         1.600272   \n",
       "\n",
       "       relative_humidity_1000hPa:p  sfc_pressure:hPa  snow_density:kgm3  \\\n",
       "0                        -0.742403          0.788712                0.0   \n",
       "1                         0.711439         -0.644171                0.0   \n",
       "2                         0.556738          1.105431                0.0   \n",
       "3                         0.968103         -0.386596                0.0   \n",
       "4                        -0.777563         -1.392092                0.0   \n",
       "...                            ...               ...                ...   \n",
       "82606                     0.860867         -0.438110                0.0   \n",
       "82607                     0.809885         -0.024082                0.0   \n",
       "82608                     0.417858          0.819237                0.0   \n",
       "82609                    -0.779321         -1.407356                0.0   \n",
       "82610                     1.245863          0.433829                0.0   \n",
       "\n",
       "       snow_depth:cm  snow_drift:idx  snow_melt_10min:mm  snow_water:kgm2  \\\n",
       "0          -0.153735       -0.005459           -0.064067        -0.380596   \n",
       "1          -0.153735       -0.005459           -0.064067        -0.168525   \n",
       "2          -0.153735       -0.005459           -0.064067        -0.380596   \n",
       "3          -0.153735       -0.005459           -0.064067         0.043547   \n",
       "4          -0.153735       -0.005459           -0.064067        -0.380596   \n",
       "...              ...             ...                 ...              ...   \n",
       "82606      -0.153735       -0.005459           -0.064067        -0.380596   \n",
       "82607      -0.153735       -0.005459           -0.064067        -0.380596   \n",
       "82608      -0.153735       -0.005459           -0.064067        -0.380596   \n",
       "82609      -0.153735       -0.005459           -0.064067        -0.380596   \n",
       "82610      -0.153735       -0.005459           -0.064067        -0.380596   \n",
       "\n",
       "       sun_azimuth:d  sun_elevation:d  super_cooled_liquid_water:kgm2  \\\n",
       "0          -0.736486         1.309619                       -0.537932   \n",
       "1          -1.508877        -1.300690                        0.407943   \n",
       "2           1.134056         0.342227                       -0.537932   \n",
       "3          -1.428432         0.185245                        0.407943   \n",
       "4          -0.175023         0.942882                       -0.537932   \n",
       "...              ...              ...                             ...   \n",
       "82606       0.797337         0.435492                       -0.537932   \n",
       "82607      -0.245692         0.480919                       -0.537932   \n",
       "82608       1.569096         0.012383                       -0.537932   \n",
       "82609       0.965445        -0.825508                       -0.537932   \n",
       "82610      -0.718394         1.215915                        0.407943   \n",
       "\n",
       "       t_1000hPa:K  total_cloud_cover:p  visibility:m  wind_speed_10m:ms  \\\n",
       "0         2.612505            -2.028697      1.098311          -0.902113   \n",
       "1        -1.074586             0.453369      0.070423          -0.219559   \n",
       "2         1.123856             0.773731      0.489176          -1.570448   \n",
       "3         0.272106             0.564320     -1.552874           0.192817   \n",
       "4        -0.280382             0.698049      0.878664           0.007959   \n",
       "...            ...                  ...           ...                ...   \n",
       "82606    -0.226667            -0.077137     -0.277584          -1.143851   \n",
       "82607    -0.295730            -2.156547      0.776563           0.462995   \n",
       "82608     1.649485             0.163869      0.461337          -0.176900   \n",
       "82609    -1.504297             0.746544      1.292383           0.790052   \n",
       "82610     1.231286             0.765648     -1.411111          -1.470909   \n",
       "\n",
       "       wind_speed_u_10m:ms  wind_speed_v_10m:ms  wind_speed_w_1000hPa:ms  \\\n",
       "0                -0.441818            -1.056949                 0.000961   \n",
       "1                 0.156150             0.915281                 0.000961   \n",
       "2                -0.147296            -0.417307                 0.000961   \n",
       "3                 0.959391            -0.110812                 0.000961   \n",
       "4                -1.245059             0.275639                 0.000961   \n",
       "...                    ...                  ...                      ...   \n",
       "82606            -0.477517             0.049099                 0.000961   \n",
       "82607            -1.539580             0.288965                 0.000961   \n",
       "82608             0.718419            -0.070834                 0.000961   \n",
       "82609            -1.798402            -0.097486                 0.000961   \n",
       "82610            -0.343644            -0.510588                 0.000961   \n",
       "\n",
       "       location       day      hour  \n",
       "0     -1.143293  0.289431 -0.649731  \n",
       "1      0.107764 -1.098440 -1.516853  \n",
       "2     -1.143293  0.435523  0.939991  \n",
       "3     -1.143293  0.088555 -1.372332  \n",
       "4      0.107764 -0.970610 -0.216171  \n",
       "...         ...       ...       ...  \n",
       "82606  1.358822 -0.824518  0.650951  \n",
       "82607 -1.143293  1.165982 -0.360691  \n",
       "82608 -1.143293  0.125078  1.373552  \n",
       "82609  0.107764 -1.317578  0.939991  \n",
       "82610  0.107764  0.389870 -0.649731  \n",
       "\n",
       "[82611 rows x 48 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Beklager ekstremt nasty kode her\n",
    "\n",
    "\n",
    "targets = pd.concat([train_a, train_b, train_c]).sample(frac=1)\n",
    "features = pd.concat([\n",
    "                     X_train_observed_a, \n",
    "                     X_train_observed_b, \n",
    "                     X_train_observed_c,\n",
    "                     X_train_estimated_a,\n",
    "                    X_train_estimated_b,\n",
    "                    X_train_estimated_c]).sample(frac=1)\n",
    "\n",
    "train_features = features.iloc[:90000,:]\n",
    "train_features = train_features.rename(columns={\"date_forecast\" : \"time\"})\n",
    "trainset = pd.merge(train_features, targets, how=\"right\", on=[\"time\",\"location\"]).dropna()\n",
    "\n",
    "eval_features = features.iloc[90000:,:]\n",
    "eval_features = eval_features.rename(columns={\"date_forecast\" : \"time\"})\n",
    "\n",
    "evalset = pd.merge(eval_features, targets, how=\"right\", on=[\"time\",\"location\"]).dropna()\n",
    "\n",
    "trainsetX = trainset.iloc[:, :-1].reset_index().iloc[:,1:]\n",
    "trainsetX[\"day\"] = trainsetX[\"time\"].dt.day_of_year\n",
    "trainsetX[\"hour\"] = trainsetX[\"time\"].dt.hour\n",
    "\n",
    "\n",
    "sample567 = trainsetX[\"time\"].apply(lambda time : time.month in[5, 6, 7])\n",
    "#display(sample_weights)\n",
    "\n",
    "\n",
    "\n",
    "trainsetX = trainsetX.iloc[:,1:]\n",
    "trainsetX[\"location\"] = trainsetX[\"location\"].map({\"A\": 0, \"B\": 1, \"C\": 2})\n",
    "\n",
    "\n",
    "dataMean = trainsetX.mean()\n",
    "dataStd = trainsetX.std()\n",
    "trainsetX = ((trainsetX-dataMean)/dataStd).fillna(value=0)\n",
    "trainsetY = trainset.iloc[:, -1:].reset_index().iloc[:,1:]\n",
    "\n",
    "\n",
    "evalsetX = evalset.iloc[:, :-1].reset_index().iloc[:, 1:]\n",
    "\n",
    "evalsetX[\"day\"] = evalsetX[\"time\"].dt.day_of_year\n",
    "evalsetX[\"hour\"] = evalsetX[\"time\"].dt.hour\n",
    "\n",
    "#get indexes of the samples from may, june, july\n",
    "eval567 = evalsetX[\"time\"].apply(lambda time : time.month in[5, 6, 7])\n",
    "\n",
    "evalsetX = evalsetX.iloc[:,1:]\n",
    "evalsetX[\"location\"] = evalsetX[\"location\"].map({\"A\": 0, \"B\": 1, \"C\": 2})\n",
    "evalsetX = ((evalsetX-dataMean)/dataStd).fillna(value=0)\n",
    "evalsetY = evalset.iloc[:, -1:].reset_index().iloc[:, 1:]\n",
    "\n",
    "\n",
    "\n",
    "#Visual of features\n",
    "display(trainsetX)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.GaussianNoise(stddev=0.03, seed=42),\n",
    "  tf.keras.layers.Dense(40, activation=\"tanh\"),\n",
    "  tf.keras.layers.Dense(30, activation=\"relu\"),\n",
    "  tf.keras.layers.Dense(15, activation=\"relu\"),\n",
    "  tf.keras.layers.Dense(5, activation=\"relu\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "166/166 [==============================] - 3s 6ms/step - loss: 251.2981 - val_loss: 139.9290\n",
      "Epoch 2/300\n",
      "166/166 [==============================] - 1s 7ms/step - loss: 123.9481 - val_loss: 165.8616\n",
      "Epoch 3/300\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 108.6019 - val_loss: 107.1156\n",
      "Epoch 4/300\n",
      "166/166 [==============================] - 1s 5ms/step - loss: 103.9484 - val_loss: 98.3397\n",
      "Epoch 5/300\n",
      "166/166 [==============================] - 1s 5ms/step - loss: 101.8609 - val_loss: 96.2110\n",
      "Epoch 6/300\n",
      "166/166 [==============================] - 1s 5ms/step - loss: 100.3983 - val_loss: 93.8731\n",
      "Epoch 7/300\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 99.3420 - val_loss: 92.5481\n",
      "Epoch 8/300\n",
      "166/166 [==============================] - 1s 5ms/step - loss: 98.6458 - val_loss: 91.9912\n",
      "Epoch 9/300\n",
      "166/166 [==============================] - 1s 6ms/step - loss: 98.0498 - val_loss: 91.8387\n",
      "Epoch 10/300\n",
      "166/166 [==============================] - 1s 5ms/step - loss: 97.9166 - val_loss: 91.5038\n",
      "Epoch 11/300\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 97.5257 - val_loss: 90.9776\n",
      "Epoch 12/300\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 97.3048 - val_loss: 90.4107\n",
      "Epoch 13/300\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 97.2028 - val_loss: 90.4427\n",
      "Epoch 14/300\n",
      "166/166 [==============================] - 1s 3ms/step - loss: 97.1162 - val_loss: 90.2939\n",
      "Epoch 15/300\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 96.9311 - val_loss: 90.3111\n",
      "Epoch 16/300\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 96.8951 - val_loss: 90.4250\n",
      "Epoch 17/300\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 96.7832 - val_loss: 90.4661\n",
      "Epoch 18/300\n",
      "166/166 [==============================] - 1s 7ms/step - loss: 96.6536 - val_loss: 90.2209\n",
      "Epoch 19/300\n",
      "166/166 [==============================] - 1s 5ms/step - loss: 96.6245 - val_loss: 90.1208\n",
      "Epoch 20/300\n",
      "166/166 [==============================] - 1s 6ms/step - loss: 96.5817 - val_loss: 89.9430\n",
      "Epoch 21/300\n",
      "166/166 [==============================] - 1s 5ms/step - loss: 96.4064 - val_loss: 89.8299\n",
      "Epoch 22/300\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 96.2707 - val_loss: 89.7464\n",
      "Epoch 23/300\n",
      "166/166 [==============================] - 1s 7ms/step - loss: 96.2100 - val_loss: 89.7621\n",
      "Epoch 24/300\n",
      "166/166 [==============================] - 1s 7ms/step - loss: 96.1598 - val_loss: 89.7092\n",
      "Epoch 25/300\n",
      "166/166 [==============================] - 1s 3ms/step - loss: 96.1147 - val_loss: 89.5743\n",
      "Epoch 26/300\n",
      "166/166 [==============================] - 1s 6ms/step - loss: 96.0972 - val_loss: 89.6601\n",
      "Epoch 27/300\n",
      "166/166 [==============================] - 1s 7ms/step - loss: 95.9021 - val_loss: 89.3889\n",
      "Epoch 28/300\n",
      "166/166 [==============================] - 1s 8ms/step - loss: 95.9101 - val_loss: 89.1979\n",
      "Epoch 29/300\n",
      "166/166 [==============================] - 1s 7ms/step - loss: 95.7881 - val_loss: 89.2570\n",
      "Epoch 30/300\n",
      "166/166 [==============================] - 1s 7ms/step - loss: 95.6180 - val_loss: 89.1990\n",
      "Epoch 31/300\n",
      "166/166 [==============================] - 1s 6ms/step - loss: 95.5391 - val_loss: 89.1572\n",
      "Epoch 32/300\n",
      "166/166 [==============================] - 1s 5ms/step - loss: 95.5364 - val_loss: 88.9476\n",
      "Epoch 33/300\n",
      "166/166 [==============================] - 1s 6ms/step - loss: 95.4390 - val_loss: 89.0395\n",
      "Epoch 34/300\n",
      "166/166 [==============================] - 2s 10ms/step - loss: 95.5343 - val_loss: 89.0845\n",
      "Epoch 35/300\n",
      "166/166 [==============================] - 3s 15ms/step - loss: 95.2551 - val_loss: 89.0577\n",
      "Epoch 36/300\n",
      "166/166 [==============================] - 1s 6ms/step - loss: 95.1394 - val_loss: 89.3054\n",
      "Epoch 37/300\n",
      "166/166 [==============================] - 1s 6ms/step - loss: 95.1275 - val_loss: 89.2068\n",
      "Epoch 38/300\n",
      "166/166 [==============================] - 2s 9ms/step - loss: 95.1013 - val_loss: 88.9235\n",
      "Epoch 39/300\n",
      "166/166 [==============================] - 1s 6ms/step - loss: 95.1114 - val_loss: 88.7190\n",
      "Epoch 40/300\n",
      "166/166 [==============================] - 1s 6ms/step - loss: 94.9330 - val_loss: 88.8957\n",
      "Epoch 41/300\n",
      "166/166 [==============================] - 1s 5ms/step - loss: 94.8679 - val_loss: 88.5995\n",
      "Epoch 42/300\n",
      "166/166 [==============================] - 1s 6ms/step - loss: 94.7477 - val_loss: 88.7905\n",
      "Epoch 43/300\n",
      "166/166 [==============================] - 1s 5ms/step - loss: 94.7805 - val_loss: 88.7852\n",
      "Epoch 44/300\n",
      "166/166 [==============================] - 1s 5ms/step - loss: 94.7412 - val_loss: 88.8320\n",
      "Epoch 45/300\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 94.6394 - val_loss: 88.4824\n",
      "Epoch 46/300\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 94.5794 - val_loss: 88.3860\n",
      "Epoch 47/300\n",
      "166/166 [==============================] - 1s 8ms/step - loss: 94.5164 - val_loss: 88.6382\n",
      "Epoch 48/300\n",
      "166/166 [==============================] - 1s 5ms/step - loss: 94.4857 - val_loss: 88.4267\n",
      "Epoch 49/300\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 94.5118 - val_loss: 88.3992\n",
      "Epoch 50/300\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 94.5040 - val_loss: 88.3524\n",
      "Epoch 51/300\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 94.2809 - val_loss: 88.5421\n",
      "Epoch 52/300\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 94.1035 - val_loss: 88.2751\n",
      "Epoch 53/300\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 94.1884 - val_loss: 88.2519\n",
      "Epoch 54/300\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 94.1827 - val_loss: 88.0574\n",
      "Epoch 55/300\n",
      "166/166 [==============================] - 1s 6ms/step - loss: 94.1552 - val_loss: 88.1202\n",
      "Epoch 56/300\n",
      "166/166 [==============================] - 1s 5ms/step - loss: 94.0805 - val_loss: 88.1206\n",
      "Epoch 57/300\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 94.0218 - val_loss: 88.2325\n",
      "Epoch 58/300\n",
      "166/166 [==============================] - 1s 5ms/step - loss: 93.9747 - val_loss: 88.0998\n",
      "Epoch 59/300\n",
      "166/166 [==============================] - 1s 5ms/step - loss: 93.8695 - val_loss: 88.1599\n",
      "Epoch 60/300\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 93.8426 - val_loss: 88.1746\n",
      "Epoch 61/300\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 93.8095 - val_loss: 87.8882\n",
      "Epoch 62/300\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 93.9124 - val_loss: 88.0336\n",
      "Epoch 63/300\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 93.7493 - val_loss: 88.1338\n",
      "Epoch 64/300\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 93.6211 - val_loss: 88.0980\n",
      "Epoch 65/300\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 93.7354 - val_loss: 87.8385\n",
      "Epoch 66/300\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 93.6002 - val_loss: 87.7972\n",
      "Epoch 67/300\n",
      "166/166 [==============================] - 1s 3ms/step - loss: 93.6759 - val_loss: 87.8168\n",
      "Epoch 68/300\n",
      "166/166 [==============================] - 1s 3ms/step - loss: 93.5710 - val_loss: 87.9637\n",
      "Epoch 69/300\n",
      "166/166 [==============================] - 1s 3ms/step - loss: 93.3305 - val_loss: 87.7121\n",
      "Epoch 70/300\n",
      "166/166 [==============================] - 1s 3ms/step - loss: 93.4119 - val_loss: 87.5879\n",
      "Epoch 71/300\n",
      "166/166 [==============================] - 1s 3ms/step - loss: 93.4451 - val_loss: 87.6292\n",
      "Epoch 72/300\n",
      "166/166 [==============================] - 1s 5ms/step - loss: 93.3682 - val_loss: 87.5084\n",
      "Epoch 73/300\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 93.2974 - val_loss: 87.6937\n",
      "Epoch 74/300\n",
      "166/166 [==============================] - 1s 5ms/step - loss: 93.3898 - val_loss: 88.7369\n",
      "Epoch 75/300\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 93.2796 - val_loss: 87.5956\n",
      "Epoch 76/300\n",
      "166/166 [==============================] - 1s 3ms/step - loss: 93.1738 - val_loss: 87.6519\n",
      "Epoch 77/300\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 93.0730 - val_loss: 87.2993\n",
      "Epoch 78/300\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 93.1948 - val_loss: 87.5594\n",
      "Epoch 79/300\n",
      "166/166 [==============================] - 1s 6ms/step - loss: 93.2349 - val_loss: 88.1255\n",
      "Epoch 80/300\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 93.0971 - val_loss: 87.5164\n",
      "Epoch 81/300\n",
      "166/166 [==============================] - 1s 7ms/step - loss: 93.1158 - val_loss: 87.3627\n",
      "Epoch 82/300\n",
      "166/166 [==============================] - 1s 6ms/step - loss: 92.8581 - val_loss: 87.4078\n",
      "Epoch 83/300\n",
      "166/166 [==============================] - 1s 5ms/step - loss: 93.0306 - val_loss: 87.2535\n",
      "Epoch 84/300\n",
      "166/166 [==============================] - 1s 7ms/step - loss: 93.0509 - val_loss: 87.3425\n",
      "Epoch 85/300\n",
      "166/166 [==============================] - 1s 5ms/step - loss: 92.8006 - val_loss: 87.6026\n",
      "Epoch 86/300\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 92.7949 - val_loss: 87.7171\n",
      "Epoch 87/300\n",
      "166/166 [==============================] - 1s 5ms/step - loss: 92.8320 - val_loss: 87.6192\n",
      "Epoch 88/300\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 92.8232 - val_loss: 87.4458\n",
      "Epoch 89/300\n",
      "166/166 [==============================] - 1s 6ms/step - loss: 92.7651 - val_loss: 87.1632\n",
      "Epoch 90/300\n",
      "166/166 [==============================] - 1s 5ms/step - loss: 92.7879 - val_loss: 87.3804\n",
      "Epoch 91/300\n",
      "166/166 [==============================] - 1s 5ms/step - loss: 92.7518 - val_loss: 87.3080\n",
      "Epoch 92/300\n",
      "166/166 [==============================] - 1s 5ms/step - loss: 92.6528 - val_loss: 87.1345\n",
      "Epoch 93/300\n",
      "166/166 [==============================] - 1s 6ms/step - loss: 92.7490 - val_loss: 87.2135\n",
      "Epoch 94/300\n",
      "166/166 [==============================] - 1s 7ms/step - loss: 92.5191 - val_loss: 87.2501\n",
      "Epoch 95/300\n",
      "166/166 [==============================] - 2s 10ms/step - loss: 92.5736 - val_loss: 87.1675\n",
      "Epoch 96/300\n",
      "166/166 [==============================] - 2s 12ms/step - loss: 92.5414 - val_loss: 87.1496\n",
      "Epoch 97/300\n",
      "166/166 [==============================] - 2s 10ms/step - loss: 92.6081 - val_loss: 87.3850\n",
      "Epoch 98/300\n",
      "166/166 [==============================] - 2s 9ms/step - loss: 92.4848 - val_loss: 87.2477\n",
      "Epoch 99/300\n",
      "166/166 [==============================] - 2s 9ms/step - loss: 92.4181 - val_loss: 87.5970\n",
      "Epoch 100/300\n",
      "166/166 [==============================] - 1s 9ms/step - loss: 92.5610 - val_loss: 87.0967\n",
      "Epoch 101/300\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 92.4600 - val_loss: 87.7754\n",
      "Epoch 102/300\n",
      "166/166 [==============================] - 1s 5ms/step - loss: 92.3591 - val_loss: 87.0357\n",
      "Epoch 103/300\n",
      "166/166 [==============================] - 1s 5ms/step - loss: 92.2846 - val_loss: 87.1232\n",
      "Epoch 104/300\n",
      "166/166 [==============================] - 1s 5ms/step - loss: 92.2060 - val_loss: 87.2292\n",
      "Epoch 105/300\n",
      "166/166 [==============================] - 1s 8ms/step - loss: 92.3586 - val_loss: 87.7969\n",
      "Epoch 106/300\n",
      "166/166 [==============================] - 1s 6ms/step - loss: 92.2980 - val_loss: 87.3475\n",
      "Epoch 107/300\n",
      "166/166 [==============================] - 1s 7ms/step - loss: 92.3364 - val_loss: 86.8677\n",
      "Epoch 108/300\n",
      "166/166 [==============================] - 1s 7ms/step - loss: 92.3889 - val_loss: 87.2706\n",
      "Epoch 109/300\n",
      "166/166 [==============================] - 2s 9ms/step - loss: 92.0302 - val_loss: 87.0344\n",
      "Epoch 110/300\n",
      "166/166 [==============================] - 1s 8ms/step - loss: 92.2460 - val_loss: 87.6060\n",
      "Epoch 111/300\n",
      "166/166 [==============================] - 1s 7ms/step - loss: 92.1489 - val_loss: 87.0443\n",
      "Epoch 112/300\n",
      "166/166 [==============================] - 1s 7ms/step - loss: 92.1080 - val_loss: 86.9547\n",
      "Epoch 113/300\n",
      "166/166 [==============================] - 1s 8ms/step - loss: 92.1632 - val_loss: 86.9116\n",
      "Epoch 114/300\n",
      "166/166 [==============================] - 1s 9ms/step - loss: 92.0265 - val_loss: 87.0775\n",
      "Epoch 115/300\n",
      "166/166 [==============================] - 1s 9ms/step - loss: 92.1407 - val_loss: 87.1327\n",
      "Epoch 116/300\n",
      "166/166 [==============================] - 1s 7ms/step - loss: 92.0853 - val_loss: 86.9293\n",
      "Epoch 117/300\n",
      "166/166 [==============================] - 2s 9ms/step - loss: 92.1038 - val_loss: 86.7160\n",
      "Epoch 118/300\n",
      "166/166 [==============================] - 1s 8ms/step - loss: 92.0020 - val_loss: 86.8893\n",
      "Epoch 119/300\n",
      "166/166 [==============================] - 1s 7ms/step - loss: 91.9123 - val_loss: 86.8479\n",
      "Epoch 120/300\n",
      "166/166 [==============================] - 1s 5ms/step - loss: 91.7262 - val_loss: 87.4719\n",
      "Epoch 121/300\n",
      "166/166 [==============================] - 1s 8ms/step - loss: 92.1911 - val_loss: 86.8258\n",
      "Epoch 122/300\n",
      "166/166 [==============================] - 1s 8ms/step - loss: 91.8339 - val_loss: 87.0109\n",
      "Epoch 123/300\n",
      "166/166 [==============================] - 1s 6ms/step - loss: 91.8396 - val_loss: 87.2615\n",
      "Epoch 124/300\n",
      "166/166 [==============================] - 1s 6ms/step - loss: 91.7844 - val_loss: 86.7446\n",
      "Epoch 125/300\n",
      "166/166 [==============================] - 1s 8ms/step - loss: 91.8869 - val_loss: 86.8670\n",
      "Epoch 126/300\n",
      "166/166 [==============================] - 2s 12ms/step - loss: 91.8114 - val_loss: 86.8172\n",
      "Epoch 127/300\n",
      "166/166 [==============================] - 1s 7ms/step - loss: 91.6368 - val_loss: 86.5924\n",
      "Epoch 128/300\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 91.6627 - val_loss: 86.6632\n",
      "Epoch 129/300\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 91.8481 - val_loss: 86.9928\n",
      "Epoch 130/300\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 91.7315 - val_loss: 87.0882\n",
      "Epoch 131/300\n",
      "166/166 [==============================] - 1s 3ms/step - loss: 91.8080 - val_loss: 86.7232\n",
      "Epoch 132/300\n",
      "166/166 [==============================] - 2s 9ms/step - loss: 91.6241 - val_loss: 86.6587\n",
      "Epoch 133/300\n",
      "166/166 [==============================] - 1s 6ms/step - loss: 91.6407 - val_loss: 86.6175\n",
      "Epoch 134/300\n",
      "166/166 [==============================] - 1s 7ms/step - loss: 91.5051 - val_loss: 87.0302\n",
      "Epoch 135/300\n",
      "166/166 [==============================] - 2s 10ms/step - loss: 91.6956 - val_loss: 86.6419\n",
      "Epoch 136/300\n",
      "166/166 [==============================] - 1s 5ms/step - loss: 91.7177 - val_loss: 86.7789\n",
      "Epoch 137/300\n",
      "166/166 [==============================] - 1s 8ms/step - loss: 91.5631 - val_loss: 86.7806\n",
      "Epoch 138/300\n",
      "166/166 [==============================] - 1s 8ms/step - loss: 91.6246 - val_loss: 86.9133\n",
      "Epoch 139/300\n",
      "166/166 [==============================] - 1s 5ms/step - loss: 91.5276 - val_loss: 86.6698\n",
      "Epoch 140/300\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 91.4992 - val_loss: 86.6023\n",
      "Epoch 141/300\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 91.6094 - val_loss: 86.9391\n",
      "Epoch 142/300\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 91.4934 - val_loss: 86.5595\n",
      "Epoch 143/300\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 91.4896 - val_loss: 86.7827\n",
      "Epoch 144/300\n",
      "166/166 [==============================] - 1s 5ms/step - loss: 91.3731 - val_loss: 86.5286\n",
      "Epoch 145/300\n",
      "166/166 [==============================] - 1s 5ms/step - loss: 91.3206 - val_loss: 86.5135\n",
      "Epoch 146/300\n",
      "166/166 [==============================] - 1s 9ms/step - loss: 91.2700 - val_loss: 87.0340\n",
      "Epoch 147/300\n",
      "166/166 [==============================] - 1s 5ms/step - loss: 91.4953 - val_loss: 86.7583\n",
      "Epoch 148/300\n",
      "166/166 [==============================] - 1s 6ms/step - loss: 91.3456 - val_loss: 86.7382\n",
      "Epoch 149/300\n",
      "166/166 [==============================] - 1s 5ms/step - loss: 91.3874 - val_loss: 86.6834\n",
      "Epoch 150/300\n",
      "166/166 [==============================] - 1s 5ms/step - loss: 91.3674 - val_loss: 86.7295\n",
      "Epoch 151/300\n",
      "166/166 [==============================] - 1s 6ms/step - loss: 91.1495 - val_loss: 86.8705\n",
      "Epoch 152/300\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 91.2651 - val_loss: 86.4709\n",
      "Epoch 153/300\n",
      "166/166 [==============================] - 1s 6ms/step - loss: 91.2241 - val_loss: 86.3710\n",
      "Epoch 154/300\n",
      "166/166 [==============================] - 1s 6ms/step - loss: 91.1708 - val_loss: 86.5704\n",
      "Epoch 155/300\n",
      "166/166 [==============================] - 1s 6ms/step - loss: 91.2422 - val_loss: 86.5588\n",
      "Epoch 156/300\n",
      "166/166 [==============================] - 1s 5ms/step - loss: 91.1134 - val_loss: 86.9016\n",
      "Epoch 157/300\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 91.2700 - val_loss: 87.0374\n",
      "Epoch 158/300\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 91.1984 - val_loss: 86.7377\n",
      "Epoch 159/300\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 91.0696 - val_loss: 86.4373\n",
      "Epoch 160/300\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 91.1637 - val_loss: 86.6224\n",
      "Epoch 161/300\n",
      "166/166 [==============================] - 1s 5ms/step - loss: 91.0412 - val_loss: 86.7251\n",
      "Epoch 162/300\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 91.1182 - val_loss: 86.5440\n",
      "Epoch 163/300\n",
      "166/166 [==============================] - 1s 5ms/step - loss: 91.0736 - val_loss: 86.5277\n",
      "Epoch 164/300\n",
      "166/166 [==============================] - 1s 5ms/step - loss: 91.0451 - val_loss: 86.6692\n",
      "Epoch 165/300\n",
      "166/166 [==============================] - 1s 5ms/step - loss: 91.0171 - val_loss: 87.0650\n",
      "Epoch 166/300\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 90.8578 - val_loss: 86.6334\n",
      "Epoch 167/300\n",
      "166/166 [==============================] - 1s 5ms/step - loss: 91.0099 - val_loss: 86.5023\n",
      "Epoch 168/300\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 91.0973 - val_loss: 86.7613\n",
      "Epoch 169/300\n",
      "166/166 [==============================] - 1s 5ms/step - loss: 91.0016 - val_loss: 86.4248\n",
      "Epoch 170/300\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 90.9627 - val_loss: 86.4565\n",
      "Epoch 171/300\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 90.8986 - val_loss: 86.4863\n",
      "Epoch 172/300\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 90.9535 - val_loss: 86.6289\n",
      "Epoch 173/300\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 90.8568 - val_loss: 87.0510\n",
      "Epoch 174/300\n",
      "166/166 [==============================] - 1s 5ms/step - loss: 90.8559 - val_loss: 86.7340\n",
      "Epoch 175/300\n",
      "166/166 [==============================] - 1s 5ms/step - loss: 90.8443 - val_loss: 86.8223\n",
      "Epoch 176/300\n",
      "166/166 [==============================] - 1s 6ms/step - loss: 90.9326 - val_loss: 86.3402\n",
      "Epoch 177/300\n",
      "166/166 [==============================] - 1s 5ms/step - loss: 90.9878 - val_loss: 86.4856\n",
      "Epoch 178/300\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 90.6323 - val_loss: 86.4876\n",
      "Epoch 179/300\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 90.8189 - val_loss: 86.5649\n",
      "Epoch 180/300\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 90.7958 - val_loss: 87.4421\n",
      "Epoch 181/300\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 90.8204 - val_loss: 86.5936\n",
      "Epoch 182/300\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 90.7661 - val_loss: 86.6538\n",
      "Epoch 183/300\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 90.5993 - val_loss: 86.6459\n",
      "Epoch 184/300\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 90.4810 - val_loss: 86.4342\n",
      "Epoch 185/300\n",
      "166/166 [==============================] - 1s 5ms/step - loss: 90.7322 - val_loss: 86.5276\n",
      "Epoch 186/300\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 90.6292 - val_loss: 86.7756\n",
      "Epoch 187/300\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 90.4652 - val_loss: 86.7042\n",
      "Epoch 188/300\n",
      "166/166 [==============================] - 1s 5ms/step - loss: 90.6516 - val_loss: 86.7989\n",
      "Epoch 189/300\n",
      "166/166 [==============================] - 1s 6ms/step - loss: 90.5898 - val_loss: 86.8574\n",
      "Epoch 190/300\n",
      "166/166 [==============================] - 1s 5ms/step - loss: 90.5202 - val_loss: 87.0275\n",
      "Epoch 191/300\n",
      "166/166 [==============================] - 1s 6ms/step - loss: 90.5005 - val_loss: 86.8596\n",
      "Epoch 192/300\n",
      "  1/166 [..............................] - ETA: 0s - loss: 69.3518"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/sondrekolberg/Documents/School/MaskinLÃ¦ring/Project/tdt4173-machine-learning/simpleNN4.ipynb Cell 9\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sondrekolberg/Documents/School/MaskinL%C3%A6ring/Project/tdt4173-machine-learning/simpleNN4.ipynb#X33sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m sample_weights \u001b[39m=\u001b[39m sample567\u001b[39m.\u001b[39mmap({\u001b[39mTrue\u001b[39;00m : \u001b[39m1.35\u001b[39m, \u001b[39mFalse\u001b[39;00m : \u001b[39m1\u001b[39m})\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sondrekolberg/Documents/School/MaskinL%C3%A6ring/Project/tdt4173-machine-learning/simpleNN4.ipynb#X33sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sondrekolberg/Documents/School/MaskinL%C3%A6ring/Project/tdt4173-machine-learning/simpleNN4.ipynb#X33sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m   optimizer\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mAdadelta(learning_rate\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sondrekolberg/Documents/School/MaskinL%C3%A6ring/Project/tdt4173-machine-learning/simpleNN4.ipynb#X33sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m   loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmean_absolute_error\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sondrekolberg/Documents/School/MaskinL%C3%A6ring/Project/tdt4173-machine-learning/simpleNN4.ipynb#X33sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m   )\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/sondrekolberg/Documents/School/MaskinL%C3%A6ring/Project/tdt4173-machine-learning/simpleNN4.ipynb#X33sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(trainsetX, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sondrekolberg/Documents/School/MaskinL%C3%A6ring/Project/tdt4173-machine-learning/simpleNN4.ipynb#X33sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m                     trainsetY, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sondrekolberg/Documents/School/MaskinL%C3%A6ring/Project/tdt4173-machine-learning/simpleNN4.ipynb#X33sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m                     batch_size\u001b[39m=\u001b[39;49m\u001b[39m500\u001b[39;49m, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sondrekolberg/Documents/School/MaskinL%C3%A6ring/Project/tdt4173-machine-learning/simpleNN4.ipynb#X33sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m                     epochs\u001b[39m=\u001b[39;49m\u001b[39m300\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sondrekolberg/Documents/School/MaskinL%C3%A6ring/Project/tdt4173-machine-learning/simpleNN4.ipynb#X33sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m                     validation_data\u001b[39m=\u001b[39;49m(evalsetX, evalsetY),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sondrekolberg/Documents/School/MaskinL%C3%A6ring/Project/tdt4173-machine-learning/simpleNN4.ipynb#X33sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m                     sample_weight\u001b[39m=\u001b[39;49msample_weights\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sondrekolberg/Documents/School/MaskinL%C3%A6ring/Project/tdt4173-machine-learning/simpleNN4.ipynb#X33sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m                     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/keras/src/engine/training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1775\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1776\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1777\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1780\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1781\u001b[0m ):\n\u001b[1;32m   1782\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1783\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1784\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1785\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    828\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 831\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    833\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    834\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    864\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    865\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    866\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 867\u001b[0m   \u001b[39mreturn\u001b[39;00m tracing_compilation\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    868\u001b[0m       args, kwds, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_config\n\u001b[1;32m    869\u001b[0m   )\n\u001b[1;32m    870\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_config \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    872\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:132\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    130\u001b[0m args \u001b[39m=\u001b[39m args \u001b[39mif\u001b[39;00m args \u001b[39melse\u001b[39;00m ()\n\u001b[1;32m    131\u001b[0m kwargs \u001b[39m=\u001b[39m kwargs \u001b[39mif\u001b[39;00m kwargs \u001b[39melse\u001b[39;00m {}\n\u001b[0;32m--> 132\u001b[0m function \u001b[39m=\u001b[39m trace_function(\n\u001b[1;32m    133\u001b[0m     args\u001b[39m=\u001b[39;49margs, kwargs\u001b[39m=\u001b[39;49mkwargs, tracing_options\u001b[39m=\u001b[39;49mtracing_options\n\u001b[1;32m    134\u001b[0m )\n\u001b[1;32m    136\u001b[0m \u001b[39m# Bind it ourselves to skip unnecessary canonicalization of default call.\u001b[39;00m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mbind(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:178\u001b[0m, in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    175\u001b[0m     args \u001b[39m=\u001b[39m tracing_options\u001b[39m.\u001b[39minput_signature\n\u001b[1;32m    176\u001b[0m     kwargs \u001b[39m=\u001b[39m {}\n\u001b[0;32m--> 178\u001b[0m   concrete_function \u001b[39m=\u001b[39m _maybe_define_function(\n\u001b[1;32m    179\u001b[0m       args, kwargs, tracing_options\n\u001b[1;32m    180\u001b[0m   )\n\u001b[1;32m    181\u001b[0m   _set_arg_keywords(concrete_function)\n\u001b[1;32m    183\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tracing_options\u001b[39m.\u001b[39mbind_graph_to_function:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:240\u001b[0m, in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    230\u001b[0m lookup_func_type, lookup_func_context \u001b[39m=\u001b[39m (\n\u001b[1;32m    231\u001b[0m     function_type_utils\u001b[39m.\u001b[39mmake_canonicalized_monomorphic_type(\n\u001b[1;32m    232\u001b[0m         args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    236\u001b[0m     )\n\u001b[1;32m    237\u001b[0m )\n\u001b[1;32m    239\u001b[0m \u001b[39mif\u001b[39;00m tracing_options\u001b[39m.\u001b[39mfunction_cache \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 240\u001b[0m   concrete_function \u001b[39m=\u001b[39m tracing_options\u001b[39m.\u001b[39;49mfunction_cache\u001b[39m.\u001b[39;49mlookup(\n\u001b[1;32m    241\u001b[0m       lookup_func_type, current_func_context\n\u001b[1;32m    242\u001b[0m   )\n\u001b[1;32m    243\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    244\u001b[0m   concrete_function \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/tensorflow/core/function/polymorphism/function_cache.py:50\u001b[0m, in \u001b[0;36mFunctionCache.lookup\u001b[0;34m(self, function_type, context)\u001b[0m\n\u001b[1;32m     48\u001b[0m   dispatch_type \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dispatch_dict[context]\u001b[39m.\u001b[39mdispatch(function_type)\n\u001b[1;32m     49\u001b[0m   \u001b[39mif\u001b[39;00m dispatch_type:\n\u001b[0;32m---> 50\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_primary[(context, dispatch_type)]\n\u001b[1;32m     52\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/tensorflow/core/function/polymorphism/function_type.py:449\u001b[0m, in \u001b[0;36mFunctionType.__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__hash__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mint\u001b[39m:\n\u001b[0;32m--> 449\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mhash\u001b[39m((\u001b[39mtuple\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparameters\u001b[39m.\u001b[39mitems()), \u001b[39mtuple\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcaptures\u001b[39m.\u001b[39mitems())))\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/tensorflow/python/framework/tensor.py:895\u001b[0m, in \u001b[0;36mDenseSpec.__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__hash__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 895\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mhash\u001b[39m((\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shape, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdtype))\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/tensorflow/python/framework/tensor.py:875\u001b[0m, in \u001b[0;36mDenseSpec.dtype\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    872\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Returns the `TensorShape` that represents the shape of the tensor.\"\"\"\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shape\n\u001b[0;32m--> 875\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m    876\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdtype\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    877\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Returns the `dtype` of elements in the tensor.\"\"\"\u001b[39;00m\n\u001b[1;32m    878\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dtype\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#weighting for samples from months matching the testset\n",
    "sample_weights = sample567.map({True : 1.35, False : 1})\n",
    "\n",
    "model.compile(\n",
    "  optimizer=tf.keras.optimizers.experimental.Adadelta(learning_rate=0.5),\n",
    "  loss='mean_absolute_error'\n",
    "  )\n",
    "\n",
    "history = model.fit(trainsetX, \n",
    "                    trainsetY, \n",
    "                    batch_size=500, \n",
    "                    epochs=300,\n",
    "                    validation_data=(evalsetX, evalsetY),\n",
    "                    sample_weight=sample_weights\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 0s 3ms/step - loss: 166.8615\n",
      "324/324 [==============================] - 1s 3ms/step - loss: 86.7120\n"
     ]
    }
   ],
   "source": [
    "\n",
    "evalset567 = evalsetX.join(evalsetY)\n",
    "evalset567 = evalset567[eval567]\n",
    "evalset567X = evalset567.iloc[:,:-1]\n",
    "evalset567Y = evalset567.iloc[:,-1:]\n",
    "\n",
    "#results only in may, june, july(since the test set only contains data from those months)\n",
    "#this should closely match the expected score on kaggle\n",
    "results1 = model.evaluate(evalset567X, evalset567Y)\n",
    "\n",
    "#results for entire eval set\n",
    "results2 = model.evaluate(evalsetX, evalsetY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/118 [==============================] - 1s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "#lagre \n",
    "\n",
    "preds = model.predict(evalsetX)\n",
    "compare = pd.concat([evalsetY, pd.DataFrame(preds)], axis=1)\n",
    "compare.to_csv(\"test1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bm/37km6rb530l8y0vv0znc0zb00000gn/T/ipykernel_69750/3652912417.py:2: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  frame = frame.fillna(method=\"ffill\")\n",
      "/var/folders/bm/37km6rb530l8y0vv0znc0zb00000gn/T/ipykernel_69750/3652912417.py:3: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  frame = frame.fillna(method=\"bfill\")\n",
      "/var/folders/bm/37km6rb530l8y0vv0znc0zb00000gn/T/ipykernel_69750/3652912417.py:2: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  frame = frame.fillna(method=\"ffill\")\n",
      "/var/folders/bm/37km6rb530l8y0vv0znc0zb00000gn/T/ipykernel_69750/3652912417.py:3: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  frame = frame.fillna(method=\"bfill\")\n",
      "/var/folders/bm/37km6rb530l8y0vv0znc0zb00000gn/T/ipykernel_69750/3652912417.py:2: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  frame = frame.fillna(method=\"ffill\")\n",
      "/var/folders/bm/37km6rb530l8y0vv0znc0zb00000gn/T/ipykernel_69750/3652912417.py:3: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  frame = frame.fillna(method=\"bfill\")\n"
     ]
    }
   ],
   "source": [
    "#Igjen beklager for nasty kode\n",
    "\n",
    "X_test_estimated_a = pd.read_parquet('A/X_test_estimated.parquet')\n",
    "X_test_estimated_b = pd.read_parquet('A/X_test_estimated.parquet')\n",
    "X_test_estimated_c = pd.read_parquet('A/X_test_estimated.parquet')\n",
    "\n",
    "X_test_estimated_a = X_test_estimated_a.iloc[:,1:]\n",
    "X_test_estimated_b = X_test_estimated_b.iloc[:,1:]\n",
    "X_test_estimated_c = X_test_estimated_c.iloc[:,1:]\n",
    "X_test_estimated_a = add_location(averageFeatures(removeNaN(X_test_estimated_a)), \"A\")\n",
    "X_test_estimated_b = add_location(averageFeatures(removeNaN(X_test_estimated_b)), \"B\")\n",
    "X_test_estimated_c = add_location(averageFeatures(removeNaN(X_test_estimated_c)), \"C\")\n",
    "\n",
    "\n",
    "X_test_estimated = pd.concat([X_test_estimated_a, X_test_estimated_b,X_test_estimated_c]).rename(columns={\"date_forecast\" : \"time\"})\n",
    "\n",
    "\n",
    "X_test_estimated_a[\"location\"] = \"A\"\n",
    "X_test_estimated_b[\"location\"] = \"B\"\n",
    "X_test_estimated_c[\"location\"] = \"C\"\n",
    "\n",
    "parse_dates = ['time']\n",
    "X_test_targets = pd.read_csv(\"test.csv\", parse_dates=parse_dates)\n",
    "\n",
    "X_test = pd.merge(X_test_estimated, X_test_targets, on=[\"time\", \"location\"], how=\"right\")\n",
    "\n",
    "X_test = X_test.iloc[:,0:-2]\n",
    "X_test[\"day\"] = X_test[\"time\"].dt.day_of_year\n",
    "X_test[\"hour\"] = X_test[\"time\"].dt.hour\n",
    "X_test = X_test.iloc[:,1:]\n",
    "X_test[\"location\"] = X_test[\"location\"].map({\"A\": 0, \"B\": 1, \"C\": 2})\n",
    "X_test = ((X_test-dataMean)/dataStd).fillna(value=0)\n",
    "\n",
    "X_test[\"snow_density:kgm3\"] = 0\n",
    "\n",
    "compare = pd.concat([X_test, evalsetX])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>absolute_humidity_2m:gm3</th>\n",
       "      <th>air_density_2m:kgm3</th>\n",
       "      <th>ceiling_height_agl:m</th>\n",
       "      <th>clear_sky_energy_1h:J</th>\n",
       "      <th>clear_sky_rad:W</th>\n",
       "      <th>cloud_base_agl:m</th>\n",
       "      <th>dew_or_rime:idx</th>\n",
       "      <th>dew_point_2m:K</th>\n",
       "      <th>diffuse_rad:W</th>\n",
       "      <th>diffuse_rad_1h:J</th>\n",
       "      <th>direct_rad:W</th>\n",
       "      <th>direct_rad_1h:J</th>\n",
       "      <th>effective_cloud_cover:p</th>\n",
       "      <th>elevation:m</th>\n",
       "      <th>fresh_snow_12h:cm</th>\n",
       "      <th>fresh_snow_1h:cm</th>\n",
       "      <th>fresh_snow_24h:cm</th>\n",
       "      <th>fresh_snow_3h:cm</th>\n",
       "      <th>fresh_snow_6h:cm</th>\n",
       "      <th>is_day:idx</th>\n",
       "      <th>is_in_shadow:idx</th>\n",
       "      <th>msl_pressure:hPa</th>\n",
       "      <th>precip_5min:mm</th>\n",
       "      <th>precip_type_5min:idx</th>\n",
       "      <th>pressure_100m:hPa</th>\n",
       "      <th>pressure_50m:hPa</th>\n",
       "      <th>prob_rime:p</th>\n",
       "      <th>rain_water:kgm2</th>\n",
       "      <th>relative_humidity_1000hPa:p</th>\n",
       "      <th>sfc_pressure:hPa</th>\n",
       "      <th>snow_density:kgm3</th>\n",
       "      <th>snow_depth:cm</th>\n",
       "      <th>snow_drift:idx</th>\n",
       "      <th>snow_melt_10min:mm</th>\n",
       "      <th>snow_water:kgm2</th>\n",
       "      <th>sun_azimuth:d</th>\n",
       "      <th>sun_elevation:d</th>\n",
       "      <th>super_cooled_liquid_water:kgm2</th>\n",
       "      <th>t_1000hPa:K</th>\n",
       "      <th>total_cloud_cover:p</th>\n",
       "      <th>visibility:m</th>\n",
       "      <th>wind_speed_10m:ms</th>\n",
       "      <th>wind_speed_u_10m:ms</th>\n",
       "      <th>wind_speed_v_10m:ms</th>\n",
       "      <th>wind_speed_w_1000hPa:ms</th>\n",
       "      <th>location</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>-1601.000000</td>\n",
       "      <td>-1601.000000</td>\n",
       "      <td>-1601.000000</td>\n",
       "      <td>-1601.000000</td>\n",
       "      <td>-1601.000000</td>\n",
       "      <td>-1601.000000</td>\n",
       "      <td>-1601.000000</td>\n",
       "      <td>-1601.000000</td>\n",
       "      <td>-1601.000000</td>\n",
       "      <td>-1601.000000</td>\n",
       "      <td>-1601.000000</td>\n",
       "      <td>-1601.000000</td>\n",
       "      <td>-1601.000000</td>\n",
       "      <td>-1601.000000</td>\n",
       "      <td>-1601.000000</td>\n",
       "      <td>-1601.000000</td>\n",
       "      <td>-1601.000000</td>\n",
       "      <td>-1601.000000</td>\n",
       "      <td>-1601.000000</td>\n",
       "      <td>-1601.000000</td>\n",
       "      <td>-1601.000000</td>\n",
       "      <td>-1601.000000</td>\n",
       "      <td>-1601.000000</td>\n",
       "      <td>-1601.000000</td>\n",
       "      <td>-1601.000000</td>\n",
       "      <td>-1601.000000</td>\n",
       "      <td>-1601.000000</td>\n",
       "      <td>-1601.000000</td>\n",
       "      <td>-1601.000000</td>\n",
       "      <td>-1601.000000</td>\n",
       "      <td>-1601.0</td>\n",
       "      <td>-1601.000000</td>\n",
       "      <td>-1.601000e+03</td>\n",
       "      <td>-1601.000000</td>\n",
       "      <td>-1601.000000</td>\n",
       "      <td>-1601.000000</td>\n",
       "      <td>-1601.000000</td>\n",
       "      <td>-1601.000000</td>\n",
       "      <td>-1601.000000</td>\n",
       "      <td>-1601.000000</td>\n",
       "      <td>-1601.000000</td>\n",
       "      <td>-1601.000000</td>\n",
       "      <td>-1601.000000</td>\n",
       "      <td>-1601.000000</td>\n",
       "      <td>-1601.000000</td>\n",
       "      <td>-1601.000000</td>\n",
       "      <td>-1601.000000</td>\n",
       "      <td>-1601.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.521573</td>\n",
       "      <td>-1.261044</td>\n",
       "      <td>-0.091874</td>\n",
       "      <td>0.721157</td>\n",
       "      <td>0.719155</td>\n",
       "      <td>-0.092815</td>\n",
       "      <td>0.275442</td>\n",
       "      <td>1.546494</td>\n",
       "      <td>0.493055</td>\n",
       "      <td>0.499370</td>\n",
       "      <td>0.360873</td>\n",
       "      <td>0.365657</td>\n",
       "      <td>0.123233</td>\n",
       "      <td>-0.701595</td>\n",
       "      <td>-0.355023</td>\n",
       "      <td>-0.186837</td>\n",
       "      <td>-0.460301</td>\n",
       "      <td>-0.226857</td>\n",
       "      <td>-0.271992</td>\n",
       "      <td>0.485721</td>\n",
       "      <td>-0.528910</td>\n",
       "      <td>0.319218</td>\n",
       "      <td>0.198926</td>\n",
       "      <td>0.048791</td>\n",
       "      <td>0.394911</td>\n",
       "      <td>0.377695</td>\n",
       "      <td>-0.341711</td>\n",
       "      <td>0.317980</td>\n",
       "      <td>0.240611</td>\n",
       "      <td>0.360465</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.156648</td>\n",
       "      <td>8.673617e-19</td>\n",
       "      <td>-0.238143</td>\n",
       "      <td>-0.001963</td>\n",
       "      <td>-0.003121</td>\n",
       "      <td>0.643898</td>\n",
       "      <td>0.409738</td>\n",
       "      <td>1.443917</td>\n",
       "      <td>0.150280</td>\n",
       "      <td>0.218347</td>\n",
       "      <td>0.089828</td>\n",
       "      <td>0.686640</td>\n",
       "      <td>-0.291306</td>\n",
       "      <td>0.046455</td>\n",
       "      <td>0.103442</td>\n",
       "      <td>0.568479</td>\n",
       "      <td>-0.000749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.319175</td>\n",
       "      <td>0.156757</td>\n",
       "      <td>0.053145</td>\n",
       "      <td>0.392134</td>\n",
       "      <td>0.391666</td>\n",
       "      <td>-0.196297</td>\n",
       "      <td>-0.304053</td>\n",
       "      <td>-0.081752</td>\n",
       "      <td>0.200449</td>\n",
       "      <td>0.197907</td>\n",
       "      <td>0.375222</td>\n",
       "      <td>0.376307</td>\n",
       "      <td>-0.086919</td>\n",
       "      <td>-1.009066</td>\n",
       "      <td>-1.225272</td>\n",
       "      <td>-1.054084</td>\n",
       "      <td>-1.322855</td>\n",
       "      <td>-1.064185</td>\n",
       "      <td>-1.084564</td>\n",
       "      <td>-0.201166</td>\n",
       "      <td>-0.168538</td>\n",
       "      <td>-0.331339</td>\n",
       "      <td>0.716886</td>\n",
       "      <td>-0.205276</td>\n",
       "      <td>-0.327796</td>\n",
       "      <td>-0.322130</td>\n",
       "      <td>-1.678613</td>\n",
       "      <td>1.247988</td>\n",
       "      <td>-0.009491</td>\n",
       "      <td>-0.316279</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.613921</td>\n",
       "      <td>8.675626e-19</td>\n",
       "      <td>-2.194844</td>\n",
       "      <td>0.292185</td>\n",
       "      <td>0.054323</td>\n",
       "      <td>-0.036357</td>\n",
       "      <td>0.467787</td>\n",
       "      <td>0.234474</td>\n",
       "      <td>-0.084450</td>\n",
       "      <td>0.107811</td>\n",
       "      <td>0.091899</td>\n",
       "      <td>-0.024375</td>\n",
       "      <td>-0.171761</td>\n",
       "      <td>-0.933963</td>\n",
       "      <td>0.011583</td>\n",
       "      <td>0.007839</td>\n",
       "      <td>-0.001980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.770734</td>\n",
       "      <td>-1.858154</td>\n",
       "      <td>0.009156</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001383</td>\n",
       "      <td>4.274718</td>\n",
       "      <td>1.913582</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.823280</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.880060</td>\n",
       "      <td>0.858809</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.248160</td>\n",
       "      <td>0.833788</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.015356</td>\n",
       "      <td>0.911727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.809239</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009862</td>\n",
       "      <td>-0.028324</td>\n",
       "      <td>1.027784</td>\n",
       "      <td>0.292528</td>\n",
       "      <td>16.639623</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.534488</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.318965</td>\n",
       "      <td>-1.434606</td>\n",
       "      <td>-0.034365</td>\n",
       "      <td>0.059527</td>\n",
       "      <td>0.078629</td>\n",
       "      <td>-0.008898</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.565322</td>\n",
       "      <td>0.134428</td>\n",
       "      <td>0.159696</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.001795</td>\n",
       "      <td>0.551402</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.058260</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.545011</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.642196</td>\n",
       "      <td>0.629219</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.297349</td>\n",
       "      <td>0.614821</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.011172</td>\n",
       "      <td>0.617628</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.086306</td>\n",
       "      <td>0.584275</td>\n",
       "      <td>0.003155</td>\n",
       "      <td>-0.003540</td>\n",
       "      <td>0.706043</td>\n",
       "      <td>-0.132967</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.561665</td>\n",
       "      <td>0.108390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.385487</td>\n",
       "      <td>-1.021303</td>\n",
       "      <td>-0.346462</td>\n",
       "      <td>0.959782</td>\n",
       "      <td>1.135299</td>\n",
       "      <td>0.049255</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.385694</td>\n",
       "      <td>0.871392</td>\n",
       "      <td>0.804761</td>\n",
       "      <td>0.122296</td>\n",
       "      <td>0.151492</td>\n",
       "      <td>0.103066</td>\n",
       "      <td>-0.126995</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.517910</td>\n",
       "      <td>0.712929</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.770055</td>\n",
       "      <td>0.754100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.340334</td>\n",
       "      <td>0.739125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008300</td>\n",
       "      <td>0.629478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.484111</td>\n",
       "      <td>0.130705</td>\n",
       "      <td>0.278753</td>\n",
       "      <td>0.169941</td>\n",
       "      <td>0.728386</td>\n",
       "      <td>-0.319121</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.548077</td>\n",
       "      <td>0.072260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.828200</td>\n",
       "      <td>-0.956406</td>\n",
       "      <td>0.017895</td>\n",
       "      <td>1.231856</td>\n",
       "      <td>1.340468</td>\n",
       "      <td>-0.192946</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.555244</td>\n",
       "      <td>0.654167</td>\n",
       "      <td>0.699174</td>\n",
       "      <td>0.792304</td>\n",
       "      <td>0.830307</td>\n",
       "      <td>0.004417</td>\n",
       "      <td>-2.285907</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.071641</td>\n",
       "      <td>0.092111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.167906</td>\n",
       "      <td>0.149860</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.278294</td>\n",
       "      <td>0.126695</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.310905</td>\n",
       "      <td>0.064377</td>\n",
       "      <td>0.695645</td>\n",
       "      <td>0.934144</td>\n",
       "      <td>1.499413</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.365700</td>\n",
       "      <td>0.116834</td>\n",
       "      <td>0.795416</td>\n",
       "      <td>-0.462061</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.570724</td>\n",
       "      <td>-0.108390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.192923</td>\n",
       "      <td>-1.967459</td>\n",
       "      <td>0.125562</td>\n",
       "      <td>0.542716</td>\n",
       "      <td>0.545145</td>\n",
       "      <td>0.369834</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.341705</td>\n",
       "      <td>-0.073967</td>\n",
       "      <td>0.074866</td>\n",
       "      <td>1.228765</td>\n",
       "      <td>1.280608</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.285907</td>\n",
       "      <td>-11.997418</td>\n",
       "      <td>-19.859019</td>\n",
       "      <td>-10.766852</td>\n",
       "      <td>-15.596203</td>\n",
       "      <td>-12.372566</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.909642</td>\n",
       "      <td>4.883095</td>\n",
       "      <td>-6.037648</td>\n",
       "      <td>-0.905155</td>\n",
       "      <td>-0.918366</td>\n",
       "      <td>-17.651448</td>\n",
       "      <td>12.520442</td>\n",
       "      <td>-0.070903</td>\n",
       "      <td>-0.929415</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.858148</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-35.421463</td>\n",
       "      <td>8.498083</td>\n",
       "      <td>0.007611</td>\n",
       "      <td>0.363905</td>\n",
       "      <td>1.634752</td>\n",
       "      <td>2.578075</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.075904</td>\n",
       "      <td>0.637279</td>\n",
       "      <td>0.607733</td>\n",
       "      <td>-1.010551</td>\n",
       "      <td>-16.639623</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.579783</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       absolute_humidity_2m:gm3  air_density_2m:kgm3  ceiling_height_agl:m  \\\n",
       "count              -1601.000000         -1601.000000          -1601.000000   \n",
       "mean                   1.521573            -1.261044             -0.091874   \n",
       "std                    0.319175             0.156757              0.053145   \n",
       "min                    0.770734            -1.858154              0.009156   \n",
       "25%                    1.318965            -1.434606             -0.034365   \n",
       "50%                    1.385487            -1.021303             -0.346462   \n",
       "75%                    1.828200            -0.956406              0.017895   \n",
       "max                    2.192923            -1.967459              0.125562   \n",
       "\n",
       "       clear_sky_energy_1h:J  clear_sky_rad:W  cloud_base_agl:m  \\\n",
       "count           -1601.000000     -1601.000000      -1601.000000   \n",
       "mean                0.721157         0.719155         -0.092815   \n",
       "std                 0.392134         0.391666         -0.196297   \n",
       "min                 0.000000         0.000000          0.001383   \n",
       "25%                 0.059527         0.078629         -0.008898   \n",
       "50%                 0.959782         1.135299          0.049255   \n",
       "75%                 1.231856         1.340468         -0.192946   \n",
       "max                 0.542716         0.545145          0.369834   \n",
       "\n",
       "       dew_or_rime:idx  dew_point_2m:K  diffuse_rad:W  diffuse_rad_1h:J  \\\n",
       "count     -1601.000000    -1601.000000   -1601.000000      -1601.000000   \n",
       "mean          0.275442        1.546494       0.493055          0.499370   \n",
       "std          -0.304053       -0.081752       0.200449          0.197907   \n",
       "min           4.274718        1.913582       0.000000          0.000000   \n",
       "25%           0.000000        1.565322       0.134428          0.159696   \n",
       "50%           0.000000        1.385694       0.871392          0.804761   \n",
       "75%           0.000000        1.555244       0.654167          0.699174   \n",
       "max           0.000000        1.341705      -0.073967          0.074866   \n",
       "\n",
       "       direct_rad:W  direct_rad_1h:J  effective_cloud_cover:p  elevation:m  \\\n",
       "count  -1601.000000     -1601.000000             -1601.000000 -1601.000000   \n",
       "mean       0.360873         0.365657                 0.123233    -0.701595   \n",
       "std        0.375222         0.376307                -0.086919    -1.009066   \n",
       "min        0.000000         0.000000                 0.000000     0.000000   \n",
       "25%        0.000223         0.001795                 0.551402     0.000000   \n",
       "50%        0.122296         0.151492                 0.103066    -0.126995   \n",
       "75%        0.792304         0.830307                 0.004417    -2.285907   \n",
       "max        1.228765         1.280608                 0.000000    -2.285907   \n",
       "\n",
       "       fresh_snow_12h:cm  fresh_snow_1h:cm  fresh_snow_24h:cm  \\\n",
       "count       -1601.000000      -1601.000000       -1601.000000   \n",
       "mean           -0.355023         -0.186837          -0.460301   \n",
       "std            -1.225272         -1.054084          -1.322855   \n",
       "min             0.000000          0.000000           0.000000   \n",
       "25%             0.000000          0.000000           0.000000   \n",
       "50%             0.000000          0.000000           0.000000   \n",
       "75%             0.000000          0.000000           0.000000   \n",
       "max           -11.997418        -19.859019         -10.766852   \n",
       "\n",
       "       fresh_snow_3h:cm  fresh_snow_6h:cm   is_day:idx  is_in_shadow:idx  \\\n",
       "count      -1601.000000      -1601.000000 -1601.000000      -1601.000000   \n",
       "mean          -0.226857         -0.271992     0.485721         -0.528910   \n",
       "std           -1.064185         -1.084564    -0.201166         -0.168538   \n",
       "min            0.000000          0.000000     0.000000          0.000000   \n",
       "25%            0.000000          0.000000     2.058260          0.000000   \n",
       "50%            0.000000          0.000000     0.000000         -0.517910   \n",
       "75%            0.000000          0.000000     0.000000         -2.071641   \n",
       "max          -15.596203        -12.372566     0.000000          0.000000   \n",
       "\n",
       "       msl_pressure:hPa  precip_5min:mm  precip_type_5min:idx  \\\n",
       "count      -1601.000000    -1601.000000          -1601.000000   \n",
       "mean           0.319218        0.198926              0.048791   \n",
       "std           -0.331339        0.716886             -0.205276   \n",
       "min            0.823280        0.000000              0.000000   \n",
       "25%            0.545011        0.000000              0.000000   \n",
       "50%            0.712929        0.000000              0.000000   \n",
       "75%            0.092111        0.000000              0.000000   \n",
       "max           -0.909642        4.883095             -6.037648   \n",
       "\n",
       "       pressure_100m:hPa  pressure_50m:hPa  prob_rime:p  rain_water:kgm2  \\\n",
       "count       -1601.000000      -1601.000000 -1601.000000     -1601.000000   \n",
       "mean            0.394911          0.377695    -0.341711         0.317980   \n",
       "std            -0.327796         -0.322130    -1.678613         1.247988   \n",
       "min             0.880060          0.858809     0.000000         0.000000   \n",
       "25%             0.642196          0.629219     0.000000         0.000000   \n",
       "50%             0.770055          0.754100     0.000000         0.000000   \n",
       "75%             0.167906          0.149860     0.000000         0.000000   \n",
       "max            -0.905155         -0.918366   -17.651448        12.520442   \n",
       "\n",
       "       relative_humidity_1000hPa:p  sfc_pressure:hPa  snow_density:kgm3  \\\n",
       "count                 -1601.000000      -1601.000000            -1601.0   \n",
       "mean                      0.240611          0.360465                0.0   \n",
       "std                      -0.009491         -0.316279                0.0   \n",
       "min                       0.248160          0.833788                0.0   \n",
       "25%                       0.297349          0.614821                0.0   \n",
       "50%                       0.340334          0.739125                0.0   \n",
       "75%                       0.278294          0.126695                0.0   \n",
       "max                      -0.070903         -0.929415                0.0   \n",
       "\n",
       "       snow_depth:cm  snow_drift:idx  snow_melt_10min:mm  snow_water:kgm2  \\\n",
       "count   -1601.000000   -1.601000e+03        -1601.000000     -1601.000000   \n",
       "mean       -0.156648    8.673617e-19           -0.238143        -0.001963   \n",
       "std        -0.613921    8.675626e-19           -2.194844         0.292185   \n",
       "min         0.000000    0.000000e+00            0.000000         0.000000   \n",
       "25%         0.000000    0.000000e+00            0.000000         0.000000   \n",
       "50%         0.000000    0.000000e+00            0.000000         0.000000   \n",
       "75%         0.000000    0.000000e+00            0.000000        -0.310905   \n",
       "max        -3.858148    0.000000e+00          -35.421463         8.498083   \n",
       "\n",
       "       sun_azimuth:d  sun_elevation:d  super_cooled_liquid_water:kgm2  \\\n",
       "count   -1601.000000     -1601.000000                    -1601.000000   \n",
       "mean       -0.003121         0.643898                        0.409738   \n",
       "std         0.054323        -0.036357                        0.467787   \n",
       "min        -0.015356         0.911727                        0.000000   \n",
       "25%        -0.011172         0.617628                        0.000000   \n",
       "50%         0.008300         0.629478                        0.000000   \n",
       "75%         0.064377         0.695645                        0.934144   \n",
       "max         0.007611         0.363905                        1.634752   \n",
       "\n",
       "       t_1000hPa:K  total_cloud_cover:p  visibility:m  wind_speed_10m:ms  \\\n",
       "count -1601.000000         -1601.000000  -1601.000000       -1601.000000   \n",
       "mean      1.443917             0.150280      0.218347           0.089828   \n",
       "std       0.234474            -0.084450      0.107811           0.091899   \n",
       "min       1.809239             0.000000      0.009862          -0.028324   \n",
       "25%       1.086306             0.584275      0.003155          -0.003540   \n",
       "50%       1.484111             0.130705      0.278753           0.169941   \n",
       "75%       1.499413             0.000000      0.365700           0.116834   \n",
       "max       2.578075             0.000000     -0.075904           0.637279   \n",
       "\n",
       "       wind_speed_u_10m:ms  wind_speed_v_10m:ms  wind_speed_w_1000hPa:ms  \\\n",
       "count         -1601.000000         -1601.000000             -1601.000000   \n",
       "mean              0.686640            -0.291306                 0.046455   \n",
       "std              -0.024375            -0.171761                -0.933963   \n",
       "min               1.027784             0.292528                16.639623   \n",
       "25%               0.706043            -0.132967                 0.000000   \n",
       "50%               0.728386            -0.319121                 0.000000   \n",
       "75%               0.795416            -0.462061                 0.000000   \n",
       "max               0.607733            -1.010551               -16.639623   \n",
       "\n",
       "          location          day         hour  \n",
       "count -1601.000000 -1601.000000 -1601.000000  \n",
       "mean      0.103442     0.568479    -0.000749  \n",
       "std       0.011583     0.007839    -0.001980  \n",
       "min       0.000000     0.534488     0.000000  \n",
       "25%       0.000000     0.561665     0.108390  \n",
       "50%       0.000000     0.548077     0.072260  \n",
       "75%       0.000000     0.570724    -0.108390  \n",
       "max       0.000000     0.579783     0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X_test.describe()-evalsetX.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_preds = pd.read_csv(\"sample_submission.csv\")\n",
    "test_preds[\"prediction\"] = model.predict(X_test)\n",
    "test_preds.to_csv(\"preds/NN_locationTimeInput_Ada_correctNormalization_sampleWeightedByMonth.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
